[
["rm1-lab-3.html", "Chapter 4 RM1: Lab 3 4.1 Pre-lab activities 4.2 In-class activities", " Chapter 4 RM1: Lab 3 4.1 Pre-lab activities This is the final lab of the first semester. In the pre-lab the focus is again on data wrangling skills and repetition of key functions they have covered in lab 1 and 2. The in-class introduces inferential analyses for the first time to coincide with their statistics lecture on chi-square. One of the key aims of this lab is to demonstrate that they have already done the difficult part of R - data wrangling - and that statistical analyses are frequently very easy to peform. We also introduce visualisations and ggplot2 so that there is a tangible output to their coding. 4.1.1 Data wrangling recap Last week we looked at using one-table Wickham verbs to filter, arrange, group_by, select, mutate and summarise. Now we will focus on working with data across two or more tables. The two main verbs we will practice adding to the Wickham six today are gather() and inner_join()and these will help you process your data for the mini-project. gather() allows us to transform a table from wide format to long format (more on this below). inner_join() allows us to combine two tables together based on common columns. A function is a tool that takes an input, performs some action, and gives an output. They are nothing more than that. If you think about it your toaster is a function: it takes bread as an input; it perfoms the action of heating it up (nicely sometimes; on both sides would be a luxury); and it gives an output, the toast. A good thing about the Wickham six functions is that they are nicely named as verbs to describe what they do - mutate() mutates (adds on a column); arrange() arranges columns, summarise() summarises, etc. In terms of remembering all the functions, the truth is you don’t have to know them all. However, through practice and repetition, you will quickly learn to remember which ones are which and what package they come from. Sort of like where to find your spoons in your kitchen - you don’t look in the fridge, and then the washing machine, and then the drawer. Nope, you learnt, by repetition, to look in the drawer first time. It’s the same with functions. Keep in mind that research methods is like a language in that the more you use it and work with it the more it makes sense. 4.1.2 Tidy Data We will use the most efficient format/layout of data which is known as Tidy Data. Any data in this format is easily processed through the tidyverse package. However, the data you work with will not always be formatted this way. If that happens then our first step is to put it into Tidy Data format. There are three fundamental rules defining Tidy Data: Each variable must have its own column. Each observation must have its own row. Each value must have its own cell (i.e. no grouping two variables together, e.g. time/date in one cell). A cell is where any specific row and column meet; a single data point in a tibble is a cell. If you’ve worked with any kind of data before, particularly if you’ve used Excel, it’s very likely that you will have used wide format data. In Wide format, each participant’s data is all in one row with multiple columns for different data points. This means that the data set tends to be very wide and you will have as many rows as you have participants. This layout can be easy to read, howver, it makes programming quite difficult. Whilst Tidy Data can be conceptually more difficult to understand at first, it means you can manipulate your data in whatever way you want very easily. 4.1.3 Analysing the Autism Specturm Quotient (AQ) To continue building your data wrangling skills in this pre-lab you will tidy data from the Autism Spectrum Quotient (AQ) questionnaire. The AQ10 is a non-diagnostic short form of the AQ with only 10 questions per participant. It is a discrete scale and the higher a participant scores on the AQ10 the more autistic-like traits they are said to display. Anyone scoring 7 or above is recommended for further diagnosis. You can see an example of the AQ10 through this link: AQ10 Example. There are 66 participants and your goal in this pre-class activity is to find an AQ score for each of them through your data-wrangling skills. There are four data files to work with that you should download from Moodle: responses.csv containing the AQ survey responses to each of the 10 questions for the 66 participants qformats.csv containing information on how a question should be coded - i.e. forward or reverse coding scoring.csv containing information on how many points a specific response should get; depending on whether it is forward or reverse coded pinfo.csv containing participant information such as Age, Sex and importantly ID number. csv stands for ‘comma separated variable’, and is a very basic way of transferring data. It really just stores numbers and text and nothing else. The great thing about being this basic is that it can be read by many different machines and does not need expensive licenses to open it. 4.1.4 Activity 1: Set-up Do the following. If you need help, consult Programming Basics and RM1: Lab 1. Open R Studio and set the working directory to your Lab 3 folder. Open a new R Markdown document and save it in your working directory. Call the file “Pre-class 3”. Download the four .csv files from Moodle and save them in your Lab 3 folder. Make sure that you do not change the file names at all. Delete the default R Markdown welcome text and insert a new code chunk that loads the package tidyverse using the library() function. 4.1.5 Activity 2: Load in the data Now you need to load in the .csv datafiles using the read_csv() function and save them as variables in the environment. For example, to load in the responses file we would type: responses &lt;- read_csv(&quot;responses.csv&quot;) Add the following lines of code to your Markdown and complete them to load in all four .csv datafiles. Use the above code as an example and name each variable the same as its original filename (minus the .csv part), again as above, e.g. responses.csv gets saved as responses. Remember to run the lines so that the data loaded in and is stored in your environment. responses &lt;- read_csv() # survey responses qformats &lt;- # question formats scoring &lt;- # scoring info pinfo &lt;- # participant information 4.1.6 Activity 3: Look at your data Now that we have the data loaded in it is always best to have a look at the data to get an idea of its layout. We showed you ways of doing this before, but you can also use the glimpse() or View() functions in your Console window and put the name of the data between the brackets to see how it is arranged. Don’t add these to your script though they are just one-offs for testing. Have a look at the data in responses to see if you think it is Tidy or not and answer the following question: The data in responses is in Tidy Wide format Explain This Answer The responses tibble is far from being tidy; each row represents multiple observations from the same participant, i.e. each row shows responses to multiple questions and there are the same number of rows as there are particpants (66) - wide format. Remember we want the data in tidy format as described above. 4.1.7 Activity 4: Gathering Data. We now have all the data we need loaded in, but in order to make it easier for us to get the AQ score for each participant, we need to change the layout of the responses tibble to Tidy Data using the gather() function. Copy the below code line to a new code chunk and run it. rlong &lt;- gather(data = responses, # the dataset we want to work on key = Question, # the name of the variable that will store what is currently the names of each column (question numbers) value = Response, # the name of the new column that will store the values (data points) Q1:Q10) # the columns we want to gather together In case you are wondering if we wanted to go back the way, and ungather the data we just gathered, we would use the spread() function: e.g. rwide &lt;- spread(rlong, Questions, Response). But we do not want to do that here so let’s not add this to the code. In the code above we have used the notation Q1:Q10. This means ’select all the columns from Q1 to Q10. We could have written out the name of each column individually, for example Q1, Q2, Q3, Q4, Q5, Q6, Q7, Q8, Q9, Q10 but obviously it is much easier to use the shorthand notation. You must be careful though to know what you are selecting. R isn’t clever enough to realise that what you want is all the Question columns - it would take any and all columns that exist between Q1 and Q10. This means that if your dataset is out of order you may end up selecting columns you didn’t mean to. Always look at your data and make sure you know the layout. Look at the new dataset rlong. Compare it to the original dataset responses and try to understand how they relate to each other. 4.1.8 Activity 5: Combining data Now the responses data is in tidy format, you are closer to being able to calculate an AQ score for each person. However, you still need some extra information: Is the question is reverse or forward scored (i.e., is strongly agree a positive or negative response)? This information is found in qformats How many points are given to give a specific response? This informatio is found in scoring. This is a typical analysis situation where different information is in different tables and you need to join them altogether. Both these pieces of information are contained in qformats and scoring respectively, but we want to join them to responses to create one informative tidy table with all the information we need. We can do this through the function inner_join(); a function to combine information in two tibbles using a column common to both tibbles. Replace the NULL values in the below code with the necessary variable names to join rlong1 and qformats by Question. If you need extra help, revisit Lab 1 In-class Activity 4 - you used the same function then! You can also check the solutions for the answer (but make sure you try yourself first). rlong2 &lt;- inner_join(x = NULL, y = NULL, by = &quot;NULL&quot;) Now view rlong2. You have matched each question with its scoring format, forward or reverse. A lot of questionnaires have some questions that are Forward scored and some questions that are Reverse scored. What does this mean? Imagine a situation where your options in replying to a question are: 1 - extremely agree, 2 - agree, 3 - neutral, 4 - disagree, 5 - extremely disagree. In a forward-scoring question you would get 1 point for extremely agree, 2 for agree, 3 for neutral, etc. In a reverse scoring question you would get 5 for extremely agree, 4 for agree, 3 for neutral, etc. The reasoning behind this shift is that sometimes agreeing or disagreeing might be more favourable depending on how the question is worded. Secondly, sometimes these questions are used just to catch people out - imagine if you had two similar questions where one has the reverse meaning of the other. In this scenario, people should respond opposites. If they respond the same then they might not be paying attention. 4.1.9 Activity 6: Combining more data Now you need to combine the information in our new table, rlong2, with the scoring table so you know how many points to attribute each question based on the answer the participant gave, and whether the question was forward or reverse coded. Again, you can use the inner_join() function, but this time the common columns found in rlong2 and scoring are QFormat and Response. To combine by two columns you just write them in sequence as shown below. **Note: when there is more than one common column between two tibbles you are joining, it is best to combine by all the columns to avoid repeat columns names in the new tibble. Copy the below line into a code chunk, run it, and then view the new object. # combine rows in rlong2 and scoring based on QFormat and Response rscores &lt;- inner_join(rlong2, scoring, c(&quot;QFormat&quot;, &quot;Response&quot;)) 4.1.10 Activity 7: Calculating the AQ Scores. You have now created rscores which has information on how each participant responded to each question and how each question should be coded and scored, all within the one tibble. All you need now is to sum the scores for each participant to get their AQ score. Based on your knowledge from last week, copy the below line into your code and replace the NULLs to obtain individual aq_scores for each participant. Save your Markdown and knit it to make sure all your code works. aq_scores &lt;- rscores %&gt;% group_by(NULL) %&gt;% # how will you group individual participants? summarise(AQ = sum(NULL)) # which column will you sum to obtain AQ scores? Helpful Hint Each participant could be grouped by their Id. If we summed up the value for each Score we might get a full AQ Score for each particpipant. 4.1.11 Activity 8: One aast thing on pipes You now have a complete code to load in your data, convert it to Tidy, combine the tables and calculate an AQ score for each participant. But, if you look at it, some of your code could be more efficient by using pipes. Go back through your code and try to rewrite it using pipes %&gt;% so that it is as efficient as possible. Helpful Hint At any point where the first argument of your function is the name of a variable created before that line, there is a good chance you could have used a pipe! Here are all the bits of this code that could be piped together into one chain: rlong &lt;- gather(responses, Question, Response, Q1:Q10) rlong2 &lt;- inner_join(rlong, qformats, \"Question\") rscores &lt;- inner_join(rlong2, scoring, c(\"QFormat\", \"Response\")) aq_scores &lt;- rscores %&gt;% group_by(Id) %&gt;% summarise(AQ = sum(Score)) You have now recapped one-table and two-table verbs. These are great to know as for example, in the above, it actually only took a handful of reproducible steps to get from messy data to tidy data; could you imagine doing this by hand in Excel through cutting and pasting? Not to mention the mistakes you could make! If you have any questions, please post them on the slack forum. 4.1.12 Activity solutions Below you will find the solutions to the above questions. Only look at them after giving the questions a good try and trying to find help on Google or Slack about any issues. 4.1.12.1 Activity 2 Activity 2 responses &lt;- read_csv(&quot;responses.csv&quot;) qformats &lt;- read_csv(&quot;qformats.csv&quot;) scoring &lt;- read_csv(&quot;scoring.csv&quot;) pinfo &lt;- read_csv(&quot;pinfo.csv&quot;) Click the tab to see the solution 4.1.12.2 Activity 5 Solution Task 5 rlong2 &lt;- inner_join(x = rlong, y = qformats, by = &quot;Question&quot;) Click the tab to see the solution 4.1.12.3 Activity 7 Solution Task 7 aq_scores &lt;- rscores %&gt;% group_by(Id) %&gt;% # group by the ID number in column Id summarise(AQ = sum(Score)) # sum column Score to obtain AQ scores. Click the tab to see the solution 4.1.12.4 Activity 8 Activity 8 aq_scores2 &lt;- responses %&gt;% # take the data in `responses` and then gather(Question, Response, Q1:Q10) %&gt;% # gather up columns Q1 to Q10, put the column names in Question and the scores in Response and then inner_join(qformats, &quot;Question&quot;) %&gt;% # join with `qformats` and match the data by the column `Question` and then inner_join(scoring, c(&quot;QFormat&quot;, &quot;Response&quot;)) %&gt;% # join with `scoring` and match the data by the columns `Qformat` and `Response` and then group_by(Id) %&gt;% # group by participant ID and then summarise(AQ = sum(Score)) # calculate the total AQ score Click the tab to see the solution 4.1.13 Test yourself You want to gather the first three columns of a file called responses (Q1, Q2, Q3), put the question numbers in a column called Jam, the responses in a column called Strawberry, and store everything in a tibble called sandwich. Fill in the box with what you would write: Explain this answer sandwich &lt;- gather(data = responses, key = Jam, values = Strawberry, Q1:Q3) gather wants the data first, then the name of the new column to store the gathered column names, then the name of the new column to store the data, and then finally which columns to gather. Complete the sentence, the higher the AQ score… the less autistic-like traits displayed has no relation to autistic-like traits the more autistic-like traits displayed Type in the AQ score (just the number) of Participant ID No. 87: Type how many participants had an AQ score of 3 (again just the number): The cut-off for the AQ10 is usually said to be around 6 meaning that anyone with a score of more than 6 should be referred for diagnostic assessment. Type in how many participants we should refer from our sample: Explain this - I dont get these answers From the link above you can see that an appropriate citation for the AQ10 would be (Allison, Auyeung, and Baron-Cohen, (2012)) As mentioned, the higher the score on the AQ10 the more autistic-like traits a participant is said to show. You could do this by code with filter(aq_scores, Id == 87), which would give you a tibble of 1x2 showing the ID number and score. If you just wanted the score you could use pull() which we havent shown you that yet: filter(aq_scores, Id == 87) %&gt;% pull(AQ). The answer is an AQ score of 2. Same as above but changing the arguement of the filter. filter(aq_scores, AQ == 3) %&gt;% count(). The answer is 13. Remember you can do this by counting but the code makes it reproducible and accurate every time. You might make mistakes. filter(aq_scores, AQ &gt; 6) %&gt;% count() or filter(aq_scores, AQ &gt;= 7) %&gt;% count(). The answer is 6. 4.2 In-class activities 4.2.1 Data analysis We have spent the last few weeks focusing on the basics of R and data wrangling. You may think that the tasks we ask you to do in R will get harder as this course progresses but that isn’t true. The hardest part of learning R is at the very beginning, trying to learn the new terminology, figuring out how to load in data and wrangle it into the format you need. It may feel like you are still struggling so it’s worth reflecting on just how far you’ve come in less than 3 weeks. You can now: Understand what functions, arguments, objects, variables, and tibbles are Read data into R Tidy data into an appropriate format Calculate a range of descriptive statistics That’s amazing! Now we’re going to move on to performing some simple inferential analyses and creating a plot to visualise the data. 4.2.2 Reminders through association For the final lab of RM1, we will focus on chi-square that you covered in the lecture last week. For this lab, we’re going to use data from Rogers, T. &amp; Milkman, K. L. (2016). Reminders through association. Psychological Science, 27, 973-986. You can read the full paper online but the short version is that the authors looked at how people remember to follow through with the intention of doing something. Although there are lots of potential reasons (e.g., some people may lack the self-control resources), Rogers and Milkman (2016) propose that some people fail to follow through simply because they forget about their good intentions. If this is the case, the authors argue, then having visual reminders to follow through on their intentions may help people remember to keep them. For example, a person may choose to put a sticker for their gym on their car window, so that every time they get in the car they remember to go to the gym. In Study 1, participants took part in an unrelated experiment but at the start of the task they were asked to return a small stack of paper clips to the reception of the building at the end of the study and if they did so the researchers would donate $1 to a charity. They were then asked if they intended to do this. Those in the reminder-through-association (RTA) condition read “Thank you! To remind you to pick up a paper clip, an elephant statuette will be sitting on the counter as you collect your payment.” This message was followed by a picture of the elephant statuette. Those in the control condition simply read “Thank you!”. What we want to do is to run a chi-square analysis to determine whether those in the RTA condition were more likely to remember to return the paperclips than those in the control condition. 4.2.3 Activity 1: Set-up Do the following. If you need help, consult Programming Basics and RM1: Lab 1. Open R Studio and set the working directory to your Lab 3 folder. Open a new R Markdown document and save it in your working directory. Call the file “In-class 3”. Download the RTA_study1.csv file from Moodle and save it in your Lab 3 folder. Make sure that you do not change the file name at all. If you are working on your own computer, install the package lsr. Remember do not install packages on university computers, they are already installed. Delete the default R Markdown welcome text and insert a new code chunk that loads the packages tidyverse and lsr using the library() function and loads the data into an object named intent_data using read_csv(). library(NULL) intent_data &lt;- read_csv(NULL) 4.2.4 Activity 2: Look at the data Using your preferred method, look at the data. It is a fairly simple data file that contains four variables for 87 participants: condition: this variable indicates which condition participants were in, 1 = reminder-through-association condition, 2 = control condition intend: this variable indicates whether particpants said they were intending to return the paperclips, 1 = yes, 0 = no actualdonate: this variable indicates whether participants actually ended up returning the paperclips and therefore donating to charity, 1 = yes, 0 = no id: this variable indicates the participant ID number 4.2.5 Activity 3: Wrangle and recode the data We need to do a little bit of wrangling to get our data into the format we need. First, we need to remove all the participants who said that they did not intend to return the paperclips (intend = 0) as we are only interested in whether people follow through on an intention. Second, to make the output easier to read, we’re going to recode condition to have text labels rather than numerical values. Use filter() to remove all participants who said that they did not intend to return the paperclips Use mutate() and recode() to recode the values in condition to make 1 = rta and 2 = control and the values in actualdonate to 1 = donated and 0 = no_donation. If you need help with this, consult Lab 3 in-class activity 7. You can do this in two separate steps, or you can use pipes. Regardless of how you do it, save the final output to an object named intent_recode. The solutions are at the end of this chapter but make sure you try it yourself and ask your peers and tutor for help first. intent_recode &lt;- Helpful hint You will need to put both sides of each recode argument (i.e., 1 and rta) in quotation marks, even though 1 and 2 are numbers, they actually represent categories rather than numerical data. intent_recode should have data from 77 participants and should look something like this: condition intend actualdonate id rta 1 donated 1 rta 1 donated 2 rta 1 donated 3 rta 1 donated 4 rta 1 donated 5 rta 1 donated 6 4.2.6 Activity 4: Descriptive statistics Next you need to calculate descriptive statistics. For frequency data these are simply counts so we can use the function count() rather than having to use summarise. We want to know how many participants are in each group (rta - donated, rta - didn’t donate, control - donated, control - didn’t donate) so we will need to use group_by to display the results for all combinations of condition and actualdonate. Replace the NULLs in the below code to calculate the number of participants in each category and save it to an object named intent_counts. intent_counts &lt;- intent_recode %&gt;% group_by(NULL, NULL) %&gt;% count() How many participants in the control condition didn’t donate? How many participants in the control condition donated? How many participants in the rta condition didn’t donate? How many participants in the rta condition donated? You may also want to calculate the percentage of people who donated in each condition, if so you can adapt the code like this: intent_percent &lt;- intent_recode %&gt;% group_by(condition, actualdonate) %&gt;% count() %&gt;% ungroup() %&gt;% # ungroups the code group_by(condition) %&gt;% # then groups it again but just by condition mutate(percent_condition = n/sum(n) * 100) condition actualdonate n percent_condition control donated 16 42.11 control no_donation 22 57.89 rta donated 29 74.36 rta no_donation 10 25.64 4.2.7 ggplot2() Now you have calculated how many participants are in each cell (or combination of the categories), however, it is also useful to create a visualisation of the data - the old saying is true, a picture is worth a thousand words. To make our data visualisations we’re going to use the package ggplot2() which was loaded as part of the tidyverse. ggplot() builds plots by combining layers (see Figure 4.1)). If you’re used to making plots in Excel this might seem a bit odd at first, however, it means that you can customise each layer and R is capable of making very complex and beautiful figures (this website gives you a good sense of what’s possible). Figure 4.1: ggplot2 layers from Field et al. (2012) 4.2.8 Activity 5: Bar plot We want to create a simple bar plot of our count data. Copy and paste the below code into a new R chunk and run it. The first line (or layer) sets up the base of the graph: the data to use and the aesthetics (what will go on the x and y axis, how the plot will be grouped). aes() can take both an x and y argument, however, with a bar plot you are just asking R to count the number of data points in each group so you don’t need to specify this. fill will separate the data into each level of the grouping variable and give it a different colour. In this case, there is a different coloured bar for each level of actualdonate. The next layer adds a geom or a shape, in this case we use geom_bar() as we want to draw a bar plot. position = \"dodge\" places the bars next to each other, rather than on top of each other. Try removing this argument and just running the code with geom_bar() to see what happens. ggplot(data = intent_recode, aes(x = condition, fill = actualdonate)) + geom_bar(position = &quot;dodge&quot;) Figure 4.2: Bar plot of RTA Study 1 data In R terms, ggplot2 is a fairly old package. As a result, the use of pipes wasn’t included when it was originally written. As you can see in the code above, the layers of the code are separated by + rather than %&gt;%. In this case, + is doing essentially the same job as a pipe - be careful not to confuse them. As you can see, the plot makes it much easier to visualise the data - participants in the RTA condition appear to have been more likely to remember to donate than those in the control condition. 4.2.9 Activity 6: Make the plot pretty As mentioned, ggplot2 allows you to customise all aspects of your plots, so let’s tidy ours up a little bit. We’re going to do the following: * Edit the labels on the x-axis, y-axis and fill * Change the colours of the bars by using scale_fill_manual() and specifying the colours we want in the values argument * Change the theme of the plot to change how it looks visually ggplot(data = intent_recode, aes(x = condition, fill = actualdonate)) + geom_bar(position = &quot;dodge&quot;) + scale_x_discrete(name = &quot;Condition&quot;, labels = c(&quot;Control&quot;, &quot;RTA&quot;)) + scale_y_continuous(name = &quot;Count&quot;) + scale_fill_manual(name = &quot;Behaviour&quot;, labels = c(&quot;Donated&quot;, &quot;Did not donate&quot;), values = c(&quot;blue&quot;, &quot;grey&quot;))+ theme_classic() (#fig:plot_edits)Prettier bar plot of RTA Study There are a few things to note about the code we just added on: * The first two lines are the same code as we used in Activity 4, what we’ve done now is add on extra layers. * If you use simple colour names then you are restricted in the options you can choose, however, if you want more flexiblity you can use hexadecimal colour codes, see here for more information. * There are multiple themes that you can apply. If you type theme_ the auto-complete will show you the options - try a few out and see which one you prefer. * If you want more information on any of these functions, remember you can look at the help documentation by typing ?function. 4.2.10 Activity 7: Chi-square So, let’s finally run that chi-square analysis to see whether our intuition from the plot holds up and there is a significant association between the grouping variables. As promised, the code is quite simple - copy and paste the below code into a new R chunk and run it. results &lt;- chisq.test(x = intent_recode$condition, # the first grouping variable y = intent_recode$actualdonate, # the second grouping variable correct = FALSE) # whether we want to apply the continuity correction results ## ## Pearson&#39;s Chi-squared test ## ## data: intent_recode$condition and intent_recode$actualdonate ## X-squared = 8.244, df = 1, p-value = 0.004089 This code looks a little different to code you’ve used up until this point as it comes from Base R. The x and y variables use the notation object$variable so our x variable could be read as \"use the variable condition from the object intent_recode. The reason that we chose not to apply the continuity correction is because this is what the analysis in the original paper did. What is the chi-square statistic? Is the p-value significant? Yes No What are the degrees of freedom for the test? Explain these answers The chi-square statistic is noted in the output as X-squared. Refer to the lecture for more information on how this number is calculated. The traditional cut-off for significance is p &lt; .05. This means that if your p-value is smaller than .05 there is a statistically significant association, that is, you would be unlikely to observe this pattern of data by chance if the null hypothesis was true. If p is larger than .05 it means that there is a higher probability that any difference you see would be likely to occur even if the null hypothesis was true. Pay attention to the decimal places, they make a huge difference! Degrees of freedom are noted as df in the output. Refer to the lecture for more information on what they are and how they are calculated. Go and find the results section in the original paper, do your numbers match the ones they report? 4.2.11 Activity 8: Additional analysis information You may have noticed that when you ran the chi-square an object appeared in the environment that saved the results of the analysis. This object is a list which is a bit different to the type of objects we’ve worked with so far. Lists don’t just contain one data table or a vector of numbers or characters, they can contain multiple different types of information and multiple different tables. We can see that our object results is a list of 9, which means it has 9 components. Click on results in the environment pane to view the contents of the list (you could also type str(list)). Figure 4.3: Contents of a list Each of these components can be viewed separately using the same object$variable notation we used above. For example, if we wanted to view the observed frequencies (refer to the lecture), we would run the following code: results$observed donated no_donation control 16 22 rta 29 10 4.2.12 Assumption checks The assumptions for chi-square are as follows: The data in the cells should be frequencies, or counts of cases rather than percentages or some other transformation of the data. The levels (or categories) of the variables are mutually exclusive. That is, a particular participant fits into one and only one group of each of the variables. Each subject may contribute data to one and only one cell in the χ2. If, for example, the same subjects are tested over time such that the comparisons are of the same subjects at Time 1, Time 2, Time 3, etc., then χ2 may not be used. The study groups must be independent. This means that a different test must be used if the two groups are related. For example, a different test must be used if the researcher’s data consists of paired samples, such as in studies in which a parent is paired with his or her child. There are 2 variables, and both are measured as categories, usually at the nominal level. While Chi-square has no rule about limiting the number of cells (by limiting the number of categories for each variable), a very large number of cells (over 20) can make it difficult to meet assumption #6 below, and to interpret the meaning of the results. The expected cell frequencies should be greater than 5. 4.2.13 Activity 9: Check the expected frequencies We know that assumptions 1-5 have been met because we know the design of the study and the type of data we have fits these criteria. The final assumption we need to test is that all expected frequencies are greater than 5. Using the same object$variable code as in Activity 7, view the expected frequencies Does the data meet assumption 6? 5\"]'> Yes - all expected frequencies are &gt; 5 No - one or more expected frequencies are &lt; 5 4.2.14 Activity 10: Effect size Although it wasn’t in the original paper, as our last step we will calculate an effect size so that we have a standardised measure of how large the association between our grouping variable is, the effect size measure for chi-square is Cramer’s V that you covered in the lecture. To calculate Cramer’s V we’re going to use the function cramersv() from the lsr package. This function is very easy to use - you copy and paste the code you gave to chisq.test() in Activity 7. eff_size &lt;- cramersV(x = intent_recode$condition, y = intent_recode$actualdonate, correct = FALSE) eff_size ## [1] 0.327207 4.2.15 Activity 11: Writing up Now that you’ve run all of the analyses you can use inline coding to help you write up your results. This isn’t something you’re going to be tested on in this course but it’s a really cool feature of Markdown so for each statistical test we’ll show you the code that does it so that you can use it in the future if you wanted to. We’re going to replicate the exact write-up of the results from the original paper (with the addition of the effect size). In the whitespace in your Markdown document, copy and paste the following (do not change anything): Those in the reminder-through-association condition performed the intended behavior at a significantly higher rate (`r round(pluck(intent_percent$percent_condition, 3),0)`%, `r pluck(intent_percent$n, 3)` out of `r pluck(intent_percent$n, 3) + pluck(intent_percent$n, 4)`) than did those in the control condition (`r round(pluck(intent_percent$percent_condition, 1),0)`, `r pluck(intent_percent$n, 1)` out of `r pluck(intent_percent$n, 1) + pluck(intent_percent$n, 2)`)), χ2(`r results$parameter`, N = `r length(intent_recode$id)`) = `r round(results$statistic,2)`, p = `r round(results$p.value, 3)`, V = `r round(eff_size, 2)`. This will knit as: Those in the reminder-through-association condition performed the intended behavior at a significantly higher rate (74%, 29 out of 39) than did those in the control condition (42, 16 out of 38)), χ2(1, N = 77) = 8.24, p = 0.004,V = 0.33. If you’re feeling comfortable with R at this point, push yourself to reverse-engineer what each bit of this inline code is doing so that you could use it yourself (remember the ?help function). 4.2.15.1 Finished! And you’re done! The second and final R Portfolio for RM1 will be available on Moodle and again will only assess you on code we have covered in this book. If you need to, take the time over the break to revise what we’ve covered so far - if you can get comfortable with the content of the last few weeks, RM2 won’t pose a problem. If you’re ok with, or even enjoying R so far then please feel free to work through this book at your own pace ahead of the scheduled classes. 4.2.16 Activity solutions 4.2.16.1 Activity 1 Activity 1 library(tidyverse) intent_data &lt;- read_csv(&quot;RTA_study1.csv&quot;) click the tab to see the solution 4.2.16.2 Activity 3 Activity 3 # solution using pipes intent_recode &lt;- intent_data %&gt;% filter(intend == 1) %&gt;% mutate(condition = recode(condition, &quot;1&quot; = &quot;rta&quot;, &quot;2&quot; = &quot;control&quot;), actualdonate = recode(actualdonate, &quot;1&quot; = &quot;donated&quot;, &quot;0&quot; = &quot;no_donation&quot;)) # solution using separate steps intent_filter &lt;- filter(intent_data, intend == 1) intent_recode &lt;- mutate(intent_filter, condition = recode(condition, &quot;1&quot; = &quot;rta&quot;, &quot;2&quot; = &quot;control&quot;), actualdonate = recode(actualdonate, &quot;1&quot; = &quot;donated&quot;, &quot;0&quot; = &quot;no_donation&quot;)) click the tab to see the solution 4.2.16.3 Activity 9 Activity 9 results$expected click the tab to see the solution 4.2.17 Test yourself ** This question is currently borked You have a dataset where gender has been coded numerically. You want to recode this to use text labels. Which code will work? mutate(gender = recode(gender, “male” = “1”, “female” = “2”, “nonbinary” = “3”)) mutate(gender = recode(gender, male = 1, “female = 2, nonbinary = 3)) mutate(gender = recode(gender,”1\" = “male”, “2” = “female”, “3” = “nonbinary”)) Explain This Answer The first option has the new and old codes in the wrong position, the second option is missing quotation marks, the third option is correct. From the below code, what would the plot have on the x-axis? exp_data gender score ggplot(data = exp_data, aes(gender, score)) From the below code, how would the bars in the plot be positioned? On top of each other Next to each other ggplot(data, aes(x = condition, fill = actualdonate)) + geom_bar() Explain This Answer Which of the following is not an argument of chisq.test() (you may need to look at the help documention to answer this question)? x y p continuity "]
]
